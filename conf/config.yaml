defaults:
  - languagemodel: ??? # language model name
  - model: 'gpt2' # model name
  - tokenizer: 'characternew' # tokenizer name
  - _self_ # self reference

# input:
train_file        : 'data/input.txt'  # training data
train_size        : 0.9     # training data size
batch_size        : 64      # B
block_size        : 128     # T
n_embed           : 64      # C
vocab_size        : ???     # V # assigned by tokenizer upon loading dataloader object

# attn:
num_heads         : 8       # H
num_layers        : 4       # L

# eval:
eval_iters        : 10      # number of iterations to evaluate
eval_interval     : 100     # interval to evaluate

# train:
max_iters         : 3000    # number of iterations to train
learning_rate     : 0.001  # learning rate
dropout           : 0.1     # dropout rate

# registry:
# optimizer         : 'adam'  # optimizer name 
# scheduler         : 'linear'